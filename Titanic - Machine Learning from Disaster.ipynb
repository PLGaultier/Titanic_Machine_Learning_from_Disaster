{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "a65aa2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Libraries\n",
    "# General purpose libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "# Machine learning libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "a0c8b82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data \n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "sample = pd.read_csv('data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "db45fe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Full name -> last name only\n",
    "def decompose_name(full_name):\n",
    "    full_name = str(full_name)\n",
    "    word_list = full_name.split()\n",
    "    if len(word_list)>1:\n",
    "        name_array = str(full_name).split()\n",
    "        return name_array[-1]\n",
    "    return(full_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "fcd17075",
   "metadata": {},
   "outputs": [],
   "source": [
    "#G/3/S -> G 3 S\n",
    "def treat_cabin(cabin): \n",
    "    my_string = str(cabin)\n",
    "    if cabin != 'Nan_Cabin': \n",
    "        cabin_1,cabin_2,cabin_3 = my_string.split('/')\n",
    "        return np.array([cabin_1,cabin_2,cabin_3])\n",
    "    return np.array(['Nan_Cabin_1','0','Nan_Cabin_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "e8661197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(dataset):\n",
    "    \n",
    "    #Split into features and label\n",
    "    if (str(dataset))=='train':\n",
    "        print('Training Dataset')\n",
    "        train_labels = train['Transported']\n",
    "        train_labels = train_labels.astype(int)\n",
    "        train_features = train.drop(['Transported','PassengerId'],axis=1)\n",
    "        \n",
    "        #print(train_labels)\n",
    "    else:\n",
    "        print('Testing Dataset')\n",
    "        train_labels = np.zeros(test.shape[0])\n",
    "        train_features = test.drop(['PassengerId'],axis=1)\n",
    "        \n",
    "        \n",
    "    #Treat the NaN values\n",
    "    labels_nan_to_zero = ['CryoSleep', 'VIP']\n",
    "    labels_nan_to_mean = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall' , 'Spa', 'VRDeck']\n",
    "\n",
    "    #Get the mode of the categorical features \n",
    "    mode_HomePlanet =  train_features['HomePlanet'].value_counts().idxmax()\n",
    "    mode_Destination =  train_features['Destination'].value_counts().idxmax()\n",
    "\n",
    "    #Replace the NaN values\n",
    "    for label in labels_nan_to_zero:\n",
    "        train_features[label] = train_features[label].fillna(0) \n",
    "    for label in labels_nan_to_mean: \n",
    "        train_features[label] = train_features[label].fillna(train_features[label].mean())\n",
    "    #For the HomePlanet and Destination, NaN replaced by the mode \n",
    "    train_features['HomePlanet'] = train_features['HomePlanet'].fillna(mode_HomePlanet)\n",
    "    train_features['Destination'] = train_features['Destination'].fillna(mode_Destination)\n",
    "    #For the Cabin and the Name, replace by a string indicating missing value \n",
    "    train_features['Cabin'] = train_features['Cabin'].fillna('Nan_Cabin')\n",
    "    train_features['Name'] = train_features['Name'].fillna('Nan_Name')\n",
    "\n",
    "    #Decompose the cabins into 3 different features\n",
    "    cabin_1_array = []\n",
    "    cabin_2_array = []\n",
    "    cabin_3_array = []\n",
    "    for cabin in train_features['Cabin']: \n",
    "        cabin_decomposed= treat_cabin(cabin)\n",
    "        cabin_1_array.append(cabin_decomposed[0])\n",
    "        cabin_2_array.append(cabin_decomposed[1])\n",
    "        cabin_3_array.append(cabin_decomposed[2])\n",
    "    train_features['cabin_1'] = cabin_1_array\n",
    "    train_features['cabin_2'] = cabin_2_array\n",
    "    train_features['cabin_3'] = cabin_3_array\n",
    "    train_features = train_features.drop(['Cabin'],axis=1)\n",
    "    \n",
    "    #Get the last name and replace the column name by the last name only\n",
    "    last_name = []\n",
    "    for name in train_features['Name']: \n",
    "        last_name.append(decompose_name(name))\n",
    "    last_name_df = pd.DataFrame(last_name)\n",
    "    #Replace Name by LastName\n",
    "    train_features['Last_Name'] = last_name_df\n",
    "    train_features = train_features.drop(['Name'],axis=1)\n",
    "    \n",
    "    #From name to unique int\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(train_features['Last_Name'])\n",
    "    last_name_encoded = le.transform(train_features['Last_Name'])\n",
    "    train_features['Last_Name_encoded'] = last_name_encoded\n",
    "    train_features = train_features.drop(['Last_Name'],axis=1)\n",
    "    \n",
    "    #Hot one encoding \n",
    "    features_one_hot = ['HomePlanet', 'Destination', 'cabin_1', 'cabin_3']\n",
    "    for feature in features_one_hot:\n",
    "        one_hot = pd.get_dummies(train_features[feature])\n",
    "        # Drop column B as it is now encoded\n",
    "        train_features = train_features.drop(feature,axis = 1)\n",
    "        # Join the encoded df\n",
    "        train_features = train_features.join(one_hot)\n",
    "        \n",
    "    #replace boolean by integer\n",
    "    features_boolean = ['CryoSleep', 'VIP']\n",
    "    for feature in features_boolean:\n",
    "        train_features[feature] = train_features[feature].astype(int)\n",
    "\n",
    "\n",
    "    \n",
    "    return train_features, train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "344a4637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = data_cleaning('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "c73c2ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Dataset\n"
     ]
    }
   ],
   "source": [
    "test_features, test_labels = data_cleaning('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "698848cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model for binary classification\n",
    "#Define the model \n",
    "#normalize features that use different scales and ranges\n",
    "normalizer = tf.keras.layers.Normalization(axis = -1)\n",
    "normalizer.adapt(np.asarray(train_features).astype('float32'))\n",
    "train_input_shape = train_features.shape[1]\n",
    "model = Sequential()\n",
    "model.add(normalizer)\n",
    "model.add(Dense(50, activation='relu', input_shape=(train_input_shape,)))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "c17654d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization_15 (Normaliza  (None, 28)               57        \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 50)                1450      \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 25)                1275      \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 25)                0         \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 10)                260       \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,053\n",
      "Trainable params: 2,996\n",
      "Non-trainable params: 57\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "7953da8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "f09892d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Epoch 1/7\n",
      "435/435 [==============================] - 1s 2ms/step - loss: 0.5164 - accuracy: 0.7322 - val_loss: 0.4771 - val_accuracy: 0.7504\n",
      "Epoch 2/7\n",
      "435/435 [==============================] - 1s 2ms/step - loss: 0.4309 - accuracy: 0.7915 - val_loss: 0.5002 - val_accuracy: 0.7487\n",
      "Epoch 3/7\n",
      "435/435 [==============================] - 1s 2ms/step - loss: 0.4107 - accuracy: 0.8027 - val_loss: 0.4880 - val_accuracy: 0.7602\n",
      "Epoch 4/7\n",
      "435/435 [==============================] - 1s 2ms/step - loss: 0.4024 - accuracy: 0.8051 - val_loss: 0.5057 - val_accuracy: 0.7585\n",
      "Epoch 5/7\n",
      "435/435 [==============================] - 1s 2ms/step - loss: 0.3952 - accuracy: 0.8112 - val_loss: 0.5329 - val_accuracy: 0.7579\n",
      "Epoch 6/7\n",
      "435/435 [==============================] - 1s 2ms/step - loss: 0.3865 - accuracy: 0.8112 - val_loss: 0.5606 - val_accuracy: 0.7493\n",
      "Epoch 7/7\n",
      "435/435 [==============================] - 1s 2ms/step - loss: 0.3870 - accuracy: 0.8126 - val_loss: 0.5254 - val_accuracy: 0.7619\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "print(\"Training model...\")\n",
    "history = model.fit(x = np.asarray(train_features).astype('float32'), y = train_labels, epochs=7, batch_size = 16, validation_split=0.2)\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "0ce12aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict\n",
    "y_test = model.predict(np.asarray(test_features).astype('float32'))\n",
    "y_test_df = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "549ae0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_thresh = np.where(y_test < 0.5, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "68e8eb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_tresh_df = pd.DataFrame(y_test_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "3329aede",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['Transported'] = y_test_tresh_df\n",
    "sample[\"Transported\"] = sample[\"Transported\"].astype(bool)\n",
    "sample.to_csv('prediction_titanic.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
